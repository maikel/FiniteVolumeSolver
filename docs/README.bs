<pre class='metadata'>
Title: User Documentation
Shortname: user-doc
Level: 1
Status: LD
Group: ag-klein
URL: https://page.mi.fu-berlin.de/ghastermann/fvm-doc/index.html
Editor: Maikel Nadolski, Freie Universität Berlin https://fu-berlin.de, maikel.nadolski@fu-berlin.de
Abstract: This is a user documentation for the Finite Volume Solver library which is developed at AG Klein, Freie Universität Berlin. The library provides a framework to solve hyperbolic equations with finite volume methods. It assumes an external structured grid library like [[AMReX]], [[SAMRAI]] or [[p4est]] to adaptively refine regions of interest. One of the main design philosophies is to make the numerical methods re-usable and consistent across different grid implementations. We provide some standard flux methods which can be used out-of-the-box with a large set of hyperbolic equations. Furthermore, a lot of helper classes exist to generate distributed grids for data management which simplifies and modernizes the usage of libraries like [[AMReX]] or [[SAMRAI]]. At last, this library is also capable of handling embedded boundaries in a dimensionally split setting as defined in [[Klein2009]].
Markup Shorthands: markdown yes
Line Numbers: on
Indent: 2
</pre>

<pre class=biblio>
{
  "AMReX": {
    "authors": [
      "Weiqun Zhang",
      "Ann Almgren"
    ],
    "href": "http://github.com/AMReX-Codes/amrex",
    "title": "AMReX Github Project"
  },
  "HDF5": {
    "authors": [
      "Tab Atkins",
      "Dirk Schultze"
    ],
    "href": "http://www.w3.org/TR/foo-bar/",
    "title": "Foo Bar Level 1",
    "status": "CR",
    "publisher": "W3C",
    "deliveredBy": [
      "http://www.w3.org/html/wg/"
    ]
  },
  "p4est": {
    "authors": [
      "Tab Atkins",
      "Dirk Schultze"
    ],
    "href": "http://www.w3.org/TR/foo-bar/",
    "title": "Foo Bar Level 1",
    "status": "CR",
    "publisher": "W3C",
    "deliveredBy": [
      "http://www.w3.org/html/wg/"
    ]
  },
  "SAMRAI": {
    "authors": [
      "Tab Atkins",
      "Dirk Schultze"
    ],
    "href": "http://www.w3.org/TR/foo-bar/",
    "title": "Foo Bar Level 1",
    "status": "CR",
    "publisher": "W3C",
    "deliveredBy": [
      "http://www.w3.org/html/wg/"
    ]
  },
  "Klein2009": {
    "authors": [
      "Rupert Klein",
      "Nikiforakis"
    ],
    "href": "http://www.w3.org/TR/foo-bar/",
    "title": "Foo Bar Level 1",
    "status": "CR",
    "publisher": "W3C",
    "deliveredBy": [
      "http://www.w3.org/html/wg/"
    ]
  }
}
</pre>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

Installation {#installation}
============================

Conan Configuration {#conan-config}
-----------------------------------

We use the C++ package manager [conan](https://conan.io) to install dependencies for this library. `conan` is a python3 package and installable via the python package manager `pip3`. To install `conan` open a terminal and use the command

```text
> pip3 install --user conan
```

to make user-wide installation. You might need to add `${HOME}/.local/bin` to your `PATH` environment variable in case of a user-wide installation.
If you have root access on your machine you can also consider doing a system-wide installation via the command

```text
> sudo pip3 install conan
```

To test whether conan is installed type `conan` in your command line window.

Expected Output:

```text
> conan
Consumer commands
  install    Installs the requirements specified in a recipe (conanfile.py or conanfile.txt).
  config     Manages Conan configuration.
  get        Gets a file or list a directory of a given reference or package.
  info       Gets information about the dependency graph of a recipe.
  search     Searches package recipes and binaries in the local cache or in a remote.
Creator commands
  new        Creates a new package recipe template with a 'conanfile.py' and optionally,
             'test_package' testing files.
  create     Builds a binary package for a recipe (conanfile.py).
  upload     Uploads a recipe and binary packages to a remote.
  export     Copies the recipe (conanfile.py & associated files) to your local cache.
  export-pkg Exports a recipe, then creates a package from local source and build folders.
  test       Tests a package consuming it from a conanfile.py with a test() method.
Package development commands
  source     Calls your local conanfile.py 'source()' method.
  build      Calls your local conanfile.py 'build()' method.
  package    Calls your local conanfile.py 'package()' method.
  editable   Manages editable packages (package that resides in the user workspace, but are
             consumed as if they were in the cache).
  workspace  Manages a workspace (a set of packages consumed from the user workspace that
             belongs to the same project).
Misc commands
  profile    Lists profiles in the '.conan/profiles' folder, or shows profile details.
  remote     Manages the remote list and the package recipes associated to a remote.
  user       Authenticates against a remote with user/pass, caching the auth token.
  imports    Calls your local conanfile.py or conanfile.txt 'imports' method.
  copy       Copies conan recipes and packages to another user/channel.
  remove     Removes packages or binaries matching pattern from local cache or remote.
  alias      Creates and exports an 'alias package recipe'.
  download   Downloads recipe and binaries to the local cache, without using settings.
  inspect    Displays conanfile attributes, like name, version and options. Works locally, in
             local cache and remote.
  help       Shows help for a specific command.
  graph      Generates and manipulates lock files.

Conan commands. Type "conan <command> -h" for help
```

As a first step, you have to create a [conan profile](https://docs.conan.io/en/latest/reference/commands/misc/profile.html), which describes which toolchain you want to use. To create an auto-detected tool-chain use the command

```text
> conan profile new default --detect
```

In the case of GCC make sure to use the C++11 ABI. Unfortunately, `conan` does not choose this by default and we have to adjust the configuration by

```text
> conan profile update settings.compiler.libcxx=libstdc++11 default
> conan profile show default
Configuration for profile default:

[settings]
os=Linux
os_build=Linux
arch=x86_64
arch_build=x86_64
compiler=gcc
compiler.version=9
compiler.libcxx=libstdc++11
build_type=Release
[options]
[build_requires]
[env]
```

Note: The library needs a minimum GCC version of 7 or a minimum LLVM clang version of 5. We regularly test in our CI at GitLab GCC version 9 and clang version 8.

We added some custom installation recipes which `conan` can use to install dependencies like [[AMReX]] or [[HDF5]]. These are stored in a `conan` repository and we need to point `conan` to this repository. This is done via the command line

```text
> conan remote add finite-volume https://api.bintray.com/conan/fub-agklein/finite-volume
```

MPI Installation {#mpi-install}
-------------------------------

Make sure to have some MPI implementation on your system such that your current `conan` profile can link against it. This can be achieved by adapting the compiler option of your profile.

CMake Installation {#cmake-install}
-----------------------------------

CMake is a build generation tool and generates build configuration as Makefiles for example.

Before we start installing all dependencies with `conan` we need to install a rather new version of `CMake`. `AMReX` requires a minimal `CMake` version of 3.14. Fortunately `CMake` is quite simple to download and binary packages can be found [here](https://cmake.org/download/).

Building the Library {#build-library}
-------------------------------------

First use git and clone the library to a local directory

```text
> git clone git@git.imp.fu-berlin.de:ag-klein/FiniteVolumeSolver.git
```

If you want to build the unit tests you need to pull `Catch2` as a git submodule. Enter the source direction and call

```text
> cd FiniteVolumeSolver/
./FiniteVolumeSolver> git submodule update --init
```

This will checkout the `develop` branch by default and create a folder named with relative path `./FiniteVolumeSolver`. Next, we create an out-of-source build directory where we want to build the library archives and example binaries.

```text
./FiniteVolumeSolver> mkdir build
./FiniteVolumeSolver> cd build
./FiniteVolumeSolver/build> cd build
```

Inside the `build` directory we use conan to install the dependencies with the options which we want to use. `AMReX` for examples has the following configurable build options:

```text
AMReX:eb = True|False [True] # enable embedded boundaries / cut-cells
AMReX:omp = True|False [True] # enable OpenMP parallelization
AMReX:dim = 1|2|3 [3] # spatial dimension used by AMReX
```

To install [[AMReX]] with embedded boundaries and without OpenMP support (there is no OpenMP support on Apple for example) use within the build directory

```text
./FiniteVolumeSolver/build> conan install <Path-to-FiniteVolumeSolver-Source-Dir> -o AMReX:dim=2 -o AMReX:omp=False
```

In our case

```text
./FiniteVolumeSolver/build> conan install ../ -o AMReX:dim=2 -o AMReX:omp=False
```

This will look into the file `FiniteVolumeSolver/conanfile.txt` and tries to locally install all dependencies which are listed there. After installing these it creates a `conanfile.cmake` in the build directory which will be read by our `CMakeLists.txt` file. This, in turn, injects all necessary include and library paths which we need to build our application. Now we use `cmake` to configure our specific build, i.e.

```text
./FiniteVolumeSolver/build> cmake ../
```

to configure a Debug build, or

```text
./FiniteVolumeSolver/build> cmake ../ -DCMAKE_BUILD_TYPE=Release
```

for a Release build. On Linux and macOS this will create Makefiles by default which you can invoke by typing

```text
./FiniteVolumeSolver/build> make
```

which should build all targets. For other systems, a more general call would be

```text
./FiniteVolumeSolver/build> cmake --build .
```

If some targets fail to build feel free to raise an issue in GitLab.

Code Overview {#code-overview}
==============================

We use a layered library design to achieve separation of concerns. 
One of the main goals is to have reusable implementations for algorithms which are independent of the concrete storage backend. 
We use namespaces to indicate the dependency on various structured grid libraries such as AMReX or SAMRAI. 
All components inside of the namespace `fub` are independent of the concrete AMR backend. Classes and functions of the namespaces `fub::amrex` or `fub::samrai` depend on their respective libraries.

This library provides tools to write driver files which form complete applications. Each driver makes its own choices on how to handle program options, input files or its output. 
You can find many example applications in the `examples/` subfolder within the Git project.
Every example composes layer for layer until a solver is built and run. 
The needs application to build up their layers in the following order

  1. [PatchHierarchy](#patch-hierarchy) (data storage)
  2. [GriddingAlgorithm](#gridding-algorithm) (algorithmic choice)
  3. [IntegratorContext](#data-integrator-context) (data storage / algorithmic choice)
  4. one or more composed LevelIntegrators (algorithmic choice)
  5. SubcycleSolver (algorithmic choice)

Note: Each layer in this list is implemented in terms of its predecessor.

Policy Pattern {#policy-pattern}
--------------------------------

To provide customization points for the many algorithmic choices in an AMR-enabled simulation we make heavy use of the so-called *policy pattern*.

> **Wikipedia**: In computer programming, the strategy pattern (also known as the policy pattern) is a behavioral software design pattern that enables selecting an algorithm at runtime. Instead of implementing a single algorithm directly, code receives run-time instructions as to which in a family of algorithms to use.

For each algorithmic customization point, we define a concept, which is simply a set of syntactic requirements.
Any type which satisfies a particular policy concept can be used as a drop-in replacement for existing algorithms to adjust the method for your special needs.
The customization points are chosen to be orthogonal and thus enable them to freely concentrate on a single aspect of the method.

<div class="example">
Any class which has a member function called `UpdateConservatively` with a sufficient function signature satisfies the policy concept for `TimeIntegrator<IntegratorContext>`.
This leads to a parametrization of the algorithm in terms of objects.
One could, in the case of a `TimeIntegrator` for example, have multiple implementations for different parallelization strategies, as in the following code snippet

```cpp
fub::amrex::HypberbolicMethod method{};
if (is_gpu_enabled) {
  method.time_integrator 
      = fub::amrex::EulerForwardTimeIntegrator(fub::execution::gpu);
} else {
  method.time_integrator 
      = fub::amrex::EulerForwardTimeIntegrator(fub::execution::openmp);
}
```

The notion of concepts will be part of the C++ language as of the C++20 standard.
With compilers which will support C++20 concepts already, this type requirement can be expressed in the code as in

```cpp
template <typename TI, typename IntegratorContext>
concept TimeIntegrator = std::copy_assignable<TI> && requires (
    TI& time_integrator, IntegratorContext& context, int level, Duration dt,
    Direction dir) {
  { time_integrator.UpdateConservatively(context, level, dt, dir) };
};
```
</div>


Data Storage: PatchHierarchy {#patch-hierarchy}
-----------------------------------------------

A `PatchHierarchy` allocates simulation data for each refinement level on a `PatchLevel` and can be either generated by a `GriddingAlgorithm` or can be initialized from a checkpoint to restart a simulation. Data on a patch hierarchy shall represent a valid spatial state at some time point and does not contain a ghost cell layer.
The allocated data can be either associated to be cell-, node- or face-centered. The required data allocation is described by an object of type `DataDescription`, which is defined as

```cpp
struct DataDescription {
  int n_cell_components{0};
  int n_node_components{0};
  int n_face_components{0};
  int dimension{AMREX_SPACEDIM};
};
```

Note: A patch hierarchy does not know what the components represent. It does not have an equation object as context and does not need it. Its only responsibility is to manage a certain amount of data over multiple levels and distributed over MPI ranks.

Note: [[AMReX]] represents hierarchies very often as pairs of `(Vector<MultiFab*>, Vector<Geometry>)` where the vector is taken over the number if refinement levels. One can interpret a `PatchHierarchy` as an equivalent representation.

Algorithmic Choice: GriddingAlgorithm {#gridding-algorithm}
-----------------------------------------------------

A gridding algorithm adds some algorithmic choices to the patch hierarchy which are needed for the box generation algorithms in the context of adaptive mesh refinement. The present gridding algorithms use the `AmrCore` class from the [[AMReX]] library to generate patches and hierarchies to cover such tagged cells. It owns a patch hierarchy and initializes or modifies it using a `TaggingMethod` policy object which masks cells that need additional refinement. In addition to the `TaggingMethod` policy, a `GriddingAlgorithm` also need boundary and initial conditions, given by `BoundaryCondition` and `InitialData` policy objects. The boundary conditions are used in communication routines to fill the ghost cell layer touching the computational domain, whereas the initial conditions are only used once at the beginning of a simulation.

<div class="example">
The following code example will create an initialized and adaptively refined patch hierarchy.
<pre class=include-code>
path: ../examples/AMReX/InitialHierarchy.cpp
highlight: c++
show: 20-1000
</pre>
This example produces the following figure and can be visualized either in VisIt, Paraview or python-yt.
<center><img width="60%" height="auto" src="img/initial_hierarchy.png"/></center>
</div>

Multiple solvers can share a common gridding algorithm and will hold a member variable of type `std::shared_ptr<GriddingAlgorithm>`.
Given a shared `GriddingAlgorithm` a solver is being able to refine the patch hierarchy or to fill ghost cell boundaries at any given time of its algorithm.
Copying a `GriddingAlgorithm` by value will deeply copy its data on each MPI rank. This can be useful to create fall-back scenarios of a simulation.

The `GriddingAlgorithm` provides three customization points. 
Their concepts `InitialData<GriddingAlgorithm>`, `TaggingMethod<GriddingAlgorithm>` and `BoundaryCondition<GriddingAlgorithm>` are defined as 

```cpp
template <typename I, typename GriddingAlgorithm>
concept InitialData = std::copy_assignable<I> && 
    requires (const I& initial_data, const GriddingAlgorithm& grid, int level) {
        { initial.InitializeData(grid, level) };
    }

template <typename T, typename GriddingAlgorithm>
concept TaggingMethod = std::copy_assignable<T> && 
    requires (const T& tagging_method, ::amrex::TagBoxArray& tags, const GriddingAlgorithm& grid, int level) {
        { tagging_method.TagCellsForRefinement(tags, grid, level) };
    }

template <typename BC, typename GriddingAlgorithm>
concept BoundaryCondition = std::copy_assignable<BC> && 
    requires (const BC& boundary_condition, ::amrex::MultiFab& data, const GriddingAlgorithm& grid, int level) {
        { boundary_condition.FillBoundary(data, grid, level) };
    }
```

You find polymorphic value types `AnyInitialData<GriddingAlgorithm>`, `AnyTaggingMethod<GriddingAlgorithm>` and `AnyBoundaryCondition<GriddingAlgorithm>` in the Finite Volume Solver library to match each one of the concepts. These polymorphic types are used to store any object of a class that satisfies those concepts.

<div class="example">
The class `fub::amrex::GriddingAlgorithm` is internally defined in something like
```cpp
class GriddingAlgorithm : private ::amrex::AmrCore {
private:
    PatchHierarchy hierarchy_;
    AnyInitialData initial_data_;
    AnyTaggingMethod tagging_method_;
    AnyBoundaryCondition boundary_condition_per_level_;

public:
    /* etc... */
};
```
</div>

Data Storage: IntegratorContext {#data-integrator-context}
----------------------------------------------------------

An `IntegratorContext` allocates, manages and provides access to additional data that is needed for every conservative AMR scheme, such as cell-centered and face-centered data arrays **with ghost layers**. It also manages face-centered data on the coarse-fine interface between two refinement levels.

<div class="example">
The following code snippet shows a simplified version of how to access cell and face-based data with ghost cells using the [[AMReX]] toolbox. This implements parallelization for GPU with a fallback to an MPI/OpenMP hybrid.

```cpp
/// \brief This function computes a conservative time update for cells in
/// direction dir
///
/// This specific implementation uses the AMReX tools to do the job
void UpdateConservatively(IntegratorContext& context, int level, Duration dt,
                          Direction dir) {
  using namespace amrex;
  MultiFab& states = context.GetScratch(level);
  const MultiFab& fluxes = context.GetFluxes(level, dir);
  const int n_conservative_variables = context.GetNConservativeVariables();
  const double dx = context.GetCellSize(level, dir);
  const double lambda = dt.count() / dx;
#ifdef _OPENMP
#pragma omp parallel if (Gpu::notInLaunchRegion())
#endif
  for (MFIter mfi(cells, TilingIfNotGPU()); mfi.isValid(); ++mfi) {
    FArrayBox& qs = cells[mfi];
    const FArrayBox& fs = fluxes[mfi];
    const Box tilebox = mfi.growntilebox();
    const Box all_faces_tilebox = surroundingNodes(tilebox, d);
    const Box all_fluxes_box = flux.box();
    const Box flux_box = all_faces_tilebox & all_fluxes_box;
    const Box cell_box = enclosedCells(flux_box);
    Array4<double> q = qs.array();
    Array4<const double> f = fs.array();
    ParallelFor(cell_box, n_conservative_variables,
                [=] AMREX_GPU_DEVICE(int i, int j, int k, int var) {
                  std::array<int, 3> iL{i, j, k};
                  std::array<int, 3> iR = Shift(iv, dir, 1);
                  q(iv, var) = q(iv, var) + lambda * (f(iL, var) - f(iR, var));
                });
  }
}
```
</div>

In addition to managing the additional data, every integrator context defines a comprehensive list of functions to deal with the various data locations. The `IntegratorContext` concept is  therefore defined by


```cpp
template <typename I>
concept IntegratorContext = std::copy_assignable<I> && requires (
      I& integrator_context, int level, Duration dt, Direction dir,
      double scale) {
  // Access PatchLevel Data
  { integrator_context.GetData(level) };
  { integrator_context.GetScratch(level) };
  { integrator_context.GetFluxes(level, dir) };

  // Coarse-fine interface interaction
  { integrator_context.ApplyFluxCorrection(level, level - 1) };
  { integrator_context.ResetCoarseFineFluxes(level, level - 1) };
  { integrator_context.AccumulateCoarseFineFluxes(level, scale, dir) };

  // Action on scratch
  { integrator_context.CoarsenConservatively(level, level - 1) };
  { integrator_context.CompleteFromCons(level) };

  // Copy data
  { integrator_context.CopyDataToScratch(level) };
  { integrator_context.CopyScratchToData(level) };

  // Fill ghost layers within scratch
  { integrator_context.FillGhostLayerTwoLevels(level, bc, level - 1, bc) };
  { integrator_context.FillGhostLayerTwoLevels(level, level - 1) };
  { integrator_context.FillGhostLayerSingleLevel(level, bc) };
  { integrator_context.FillGhostLayerSingleLevel(level) };

  // Reallocate internal data from level 
  { integrator_context.ResetHierarchyConfiguration(level) };
};
```

This is the minimum amount of functions needed to build common conservative AMR schemes on top of an AMR library like [[AMReX]] or [[SAMRAI]]. The implementation of an `IntegratorContext` will, in general, be very library-specific. The layers after the `IntegratorContext` describe parts of the AMR time integration which are implemented on those concepts only.

Nevertheless, we still refine this concept to better fit the dimensionally split time integration.

```cpp
template <typename I>
concept DimensionalSplitIntegratorContext = IntegratorContext<I> && requires (
      I& integrator_context, int level, Duration dt, Direction dir,
      double scale) {
  { integrator_context.ComputeNumericFluxes(level, dt, dir) };
  { integrator_context.ComputeStableDt(level, dir) };
  { integrator_context.UpdateConservatively(level, dir) };
};
```

The functions `ComputeStableDt`, `ComputeNumericFluxes`, `UpdateConservatively` and `CompleteFromCons` are customization points of a `DimensionalSplitIntegratorContext`. I. e. one needs to provide objects for the policy concepts `FluxMethod<IntegratorContext>`, `TimeIntegrator<IntegratorContext>` and `CompleteFromConsReconstruction<IntegratorContext>` to define the behaviour of those functions.

Algorithmic Choice: IntegratorContext {#algorithm-choice-integrator-context}
----------------------------------------------------------------------------

We now describe the customization points for an integrator context.
Its concepts `FluxMethod<IntegratorContext>`, `TimeIntegrator<IntegratorContext>` and `CompleteFromConsReconstruction<IntegratorContext>` are defined as 

```cpp
template <typename FM, typename IntegratorContext>
concept FluxMethod = std::copy_assignable<FM> && requires (
    FM& flux_method, IntegratorContext& context, int level, Duration dt,
    Direction dir) {
  { flux_method.ComputeNumericFlux(context, level, dt, dir) };
  { flux_method.ComputeStableDt(context, level, dir) } -> Duration;
  { FM::GetStencilSize() } -> std::integral_constant<int, StencilSize>;
};

template <typename TI, typename IntegratorContext>
concept TimeIntegrator = std::copy_assignable<TI> && requires (
    TI& time_integrator, IntegratorContext& context, int level, Duration dt,
    Direction dir) {
  { time_integrator.UpdateConservatively(context, level, dt, dir) };
};

template <typename R, typename IntegratorContext>
concept CompleteFromConsReconstruction = std::copy_assignable<R> && requires(
    R& reconstruct, IntegratorContext& context, int level) {
  { reconstruct.CompleteFromCons(context, level) };
};
```

The member function `ComputeStableDt` shall return a time step size \( \Delta t \) such that the CFL condition for the time integration is satisfied.
The `ComputeNumericFluxes` shall fill the face-centered flux arrays in the specified direction which will be used by the `TimeIntegrator` to update the conservative state variables.

The `TimeIntegrator` provides the usual conservative scheme for cell-based time updates

\[  u^{n+1}_i = u^n_i + \frac{\Delta t}{\Delta x} \left( F^n_{i - \frac 12} - F^n_{i + \frac 12} \right). \]

The numerical fluxes \( F^n_i \) in this update denote the fluxes on the faces of the specified direction and are computed by the `FluxMethod` which is configured for this integrator context.

An AMR integration scheme may use the `CompleteFromConsReconstruction` policy object whenever it changes the conservative variables to establish a valid state across all fields in the patch hierarchy.

We collect the three customization points for the `IntegratorContext` in a class which we call `HyperbolicMethod<IntegratorContext>`.
It is defined as

```cpp
template <typename IntegratorContext>
struct HyperbolicMethod {
  AnyFluxMethod flux_method;
  AnyTimeIntegrator time_integrator;
  AnyCompleteFromConsReconstruction reconstruct;
};
```

<div class="example">
To construct an `IntegratorContext` object one needs to provide a `GriddingAlgorithm` and a `HyperbolicMethod`.
The following code snippet shows how a concrete integrator context might be constructed in a driver file.

```cpp
void MyMain(const fub::ProgramOptions& opts) {
  std::chrono::steady_clock::time_point wall_time_reference =
      std::chrono::steady_clock::now();

  fub::amrex::ScopeGuard guard{};

  fub::Advection2d equation{{1.0, 1.0}};
  fub::SeverityLogger log = fub::GetInfoLogger();

  fub::amrex::CartesianGridGeometry geometry = fub::GetOptions(opts, "GridGeometry");
  BOOST_LOG(log) << "GridGeometry:";
  geometry.Print(log);

  fub::amrex::PatchHierarchyOptions hier_opts = fub::GetOptions(opts, "PatchHierarchy");
  BOOST_LOG(log) << "PatchHierarchy:";
  hier_opts.Print(log);
 
  using State = fub::Advection2d::Complete;
  fub::amrex::GradientDetector gradient{equation,
                                        std::pair{&State::mass, 1e-3}};

  std::shared_ptr grid = std::make_shared<fub::amrex::GriddingAlgorithm>(
      fub::amrex::PatchHierarchy(equation, geometry, hier_opts), CircleData{},
      fub::amrex::TagAllOf(gradient, fub::amrex::TagBuffer(2)));
  grid->InitializeHierarchy(0.0);

  fub::amrex::HyperbolicMethod method{
      fub::amrex::FluxMethod(fub::GodunovMethod{equation}),
      fub::amrex::EulerForwardTimeIntegrator(), fub::amrex::NoReconstruction{}};

  fub::amrex::IntegratorContext context(grid, method);
  
  // Now further use the context to do some things...
}
```
</div>

In addition to computing the mathematical correct formula, an object that satisfies `FluxMethod<IntegratorContext>` needs to repeat the logic of how to parallelize and how to iterate over the multi-dimensional index space.
We recognize that these are two orthogonal concerns which are both hard to get right. 
To ease the burden for authors of a `FluxMethod` we introduced some helper classes which separate these concerns. They will be discussed in more detail in <a href="#flux-method-framework">Chapter 3</a>.

LevelIntegrator {#level-integrator}
-----------------------------------

Level integrators have the task to advance the solution in time for a single refinement level only.
They will be used by larger subcycle schemes which may, in general, do smaller time steps on finer refinement levels.
We define the concept `LevelIntegrator` such that it provides two functions `AdvanceLevelNonRecursively` and `ComputeStableDt`.


```cpp
template <typename L>
concept LevelIntegrator = std::copy_assignable<L> && requires (const L& level_integrator, int level, Duration dt, std::pair<int, int> subcycle) {
  { level_integrator.AdvanceLevelNonRecursively(level, dt, subcycle) };
  { level_integrator.ComputeStableDt(level) } -> Duration;
};
```

The name `AdvanceLevelNonRecursively` emphasizes that this function will be called within a recursive subcycle algorithm.
We call level integrators which provide an integrator context `HyperbolicSystemLevelIntegrator`.
An integrator context extents an level integrators with functions such as `ApplyFluxCorrection`, `CoarsenConservatively` or `CompleteFromCons`.
These functions will be used by a subcycle algorithm to maintain the conservation of the solution across refinement levels.

```cpp
template <typename HS>
concept HyperbolicSystemLevelIntegrator = LevelIntegrator<S> && requires (const L& level_integrator) {
  // Access underlying data storage implementation
  { level_integrator.GetIntegratorContext() } -> IntegratorContext;
};
```

This library includes currently the following list of level integrators

- `DimensionalSplitLevelIntegrator` (satisfies `HyperbolicSystemLevelIntegrator`)
- `SystemSourceLevelIntegrator` (satisfies `HyperboilcSystemLevelIntegrator`)
- `BK19LevelIntegrator` (satisfies `HyperbolicSystemLevelIntegrator`)
- `KineticSourceTerm` (satisfies `LevelIntegrator`)
- `AxialSourceTerm` (satisfies `LevelIntegrator`)



Framework for defining FluxMethods {#flux-method-framework}
===========================================================

The `FluxMethod<IntegratorContext>` policy is very generic and allows all kinds of possible logic in user-defined flux methods. 
We provide adapter classes to separate the technical aspects of computing those numerical fluxes from the mathematical ones.
To achieve this separation we begin by introducing the notion of an equation.
An equation gives context to the components of a multi-dimensional array and provides the mathematical dependencies needed.
Using those tools we allow a formulation \( F(q(x, t), dx, dt) \) of flux methods, which depend on a stencil of equation states only.

Equation: Conservative and Complete States {#cons-comp-states}
----------------------------------------------------

The Finite Volume Solver defines so-called equation classes, for example, `Advection2d` or `PerfectGas<Rank>`.
Each equation defines two kinds of states: `Conservative` and `Complete` states.
The conservative states contain variables which see a hyperbolic time update of a time integrator.
The complete state variables are a superset of the conservative ones and may define more auxiliary member variables.
This is reasonable for variables which are needed very often but have a high computation cost.
The complete state is the location to cache those expensive computations.

<div class=example>
For example, the template class `template <int Rank> class PerfectGas` defines the conservative variables

```cpp
template <int Rank> struct PerfectGasConservative {
  double density;
  Array<double, Rank> momentum;
  double energy;
};
```

and the complete state variables are

```cpp
template <int Rank> struct PerfectGasComplete : PerfectGasConservative<Rank> {
  double pressure;
  double speed_of_sound;
};
```
</div>

Given a `MultiFab` object we can iterate over all local `FArrayBox` objects using the `MFIter` iterator as in this simplified example:

```cpp
template <typename Function>
void DoSomethingForEachFArrayBox(MultiFab& multifab) {
  for (MFIter mfi(multifab); mfi.isValid(); ++mfi) {
    FArrayBox& fab = multifab[mfi];
    // do something...
  }
}
```

A `FArrayBox` is a container type in [[AMReX]] that stores a multi-dimensional data array for a single patch.
By using an equation object we can *view* this `FArrayBox` as a set of multi-dimensional arrays for each variable/

Implement a new FluxMethod, the simple case {#implement-flux-method-simple}
------------------------------------------------------------------------

A class `FM` satisfies the concept `FluxMethod<Equation, StencilSize>` if the following constraints are satisfied.

```cpp
template <typename FM, typename Equation, int StencilSize>
concept FluxMethod = requires (FM& flux_method,
                               Conservative<Equation> cons,
                               span<Complete<Equation>, StencilSize> stencil,
                               double dx, Duration dt, int dir) {
  { flux_method.ComputeNumericFlux(cons, stencil, dx, dt, dir) };
  { flux_method.ComputeStableDt(stencil, dx, dir) } -> Duration;
  { FM::GetStencilSize() } -> std::integral_constant<int, StencilSize>;
};
```

<div class="example">
For example, the following class `MusclHancockMethod` satisfies this concept.

```cpp
struct MusclHancockMethod {
    using Conservative = ::Conservative<PerfectGas<2>>;
    using Complete = ::Complete<PerfectGas<2>>;

    void ComputeNumericFlux(Conservative& cons, span<const Complete, 4> stencil,
                              double dx, Duration dt, int dir);

    Druation ComputeStableDt(span<const Complete, 4> stencil, double dx, int dir);

    std::integral_constant<int, 4> GetStencilSize() const noexcept { return {}; }
};
```

The implemented MUSCL-type flux methods for an equation `Equation` satisfy `FluxMethod<Equation, 4>` and are implemented in two steps.
First, we reconstruct a state to the left and the right the face in question.
This gives a reduction of the stencil array from `Complete state[4]` to `Complete reconstruced_states[2]`.
Secondly, we call a (lower-order) base method `BaseFM` which satisfies `FluxMethod<Equation, 2>`.
</div>
